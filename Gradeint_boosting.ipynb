{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load image data\n",
    "def load_data(dir_list, image_size):\n",
    "    data = []\n",
    "    label = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in os.listdir(directory):\n",
    "            image = cv.imread(os.path.join(directory, filename), 0)\n",
    "            image = cv.resize(image, dsize=(image_width, image_height), interpolation=cv.INTER_CUBIC)\n",
    "            image = image / 255.0\n",
    "            image = image.astype(np.float32)\n",
    "            data.append(image.flatten())  # Flatten the image to use with Gradient Boosting\n",
    "            if directory == 'yes':\n",
    "                label.append(1)  # Tumor\n",
    "            else:\n",
    "                label.append(0)  # No tumor\n",
    "    data_array = np.array(data)\n",
    "    label = np.array(label) \n",
    "    return data_array, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "x, y = load_data(['yes', 'no'], (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:\n",
      "(2400, 65536) (2400,)\n",
      "(600, 65536) (600,)\n",
      "Output Shape:\n",
      "(2400, 65536) (2400,)\n",
      "(600, 65536) (600,)\n",
      "(600, 65536) (600,)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "def split_data(test_size=0.2, log=True):\n",
    "    x_train, x_test_val, y_train, y_test_val = train_test_split(x, y, test_size=test_size, shuffle=True)\n",
    "    if log:\n",
    "        print('Input Shape:')\n",
    "        print(x_train.shape, y_train.shape)\n",
    "        print(x_test_val.shape, y_test_val.shape)\n",
    "    x_test = x_test_val\n",
    "    x_val = x_test_val\n",
    "    y_test = y_test_val\n",
    "    y_val = y_test_val\n",
    "    if log:\n",
    "        print('Output Shape:')\n",
    "        print(x_train.shape, y_train.shape)\n",
    "        print(x_test.shape, y_test.shape)\n",
    "        print(x_val.shape, y_val.shape)\n",
    "    return x_train, x_test, y_train, y_test, x_val, y_val\n",
    "\n",
    "x_train, x_test, y_train, y_test, x_val, y_val = split_data()\n",
    "validation_dataset = (x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Model\n",
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.estimators = []\n",
    "        self.predictions = []\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Initialize predictions\n",
    "        self.predictions = np.zeros(len(y))\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - self.predictions  # Compute residuals\n",
    "            tree = DecisionTreeRegressor(max_depth=3)  # Initialize decision tree regressor\n",
    "            tree.fit(X, residuals)  # Fit decision tree to residuals\n",
    "            self.estimators.append(tree)  # Add decision tree to list of estimators\n",
    "            predictions = tree.predict(X)  # Make predictions using current tree\n",
    "            self.predictions += self.learning_rate * predictions  # Update predictions with weighted predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.estimators:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return np.sign(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting Model\n",
    "gb_model = GradientBoosting(n_estimators=100, learning_rate=0.1)\n",
    "gb_model.train(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Gradient Boosting model\n",
    "def save_model(model, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Save the trained Gradient Boosting model\n",
    "save_model(gb_model, 'gradient_boosting_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model, load_model, save_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping ,CSVLogger\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shuffle\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPool2D, Flatten, Dense,Dropout\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping ,CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from math import ceil\n",
    "import pandas as pd \n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import keras \n",
    "from tensorflow.keras import datasets, layers, models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(dir_list, image_size):\n",
    "\n",
    "\n",
    "    # load all images in a directory\n",
    "    data = []\n",
    "    label = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in os.listdir(directory):\n",
    "            \n",
    "            image = cv.imread(directory + '/' + filename,0)\n",
    "\n",
    "            image = cv.resize(image, dsize=(image_width, image_height), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "            image = image / 255.0\n",
    "            image= image.astype(np.float32)\n",
    "\n",
    "            data.append(image)\n",
    "\n",
    "            if directory == 'yes':\n",
    "                label.append([1]) ## have tumor\n",
    "                \n",
    "            else:\n",
    "                label.append([0]) ## donot have tumor \n",
    "            \n",
    "\n",
    "    data_array = np.array(data)\n",
    "    label = np.array(label) \n",
    "    return data_array, label\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=load_data(['yes','no'],(256,256))\n",
    "# print(x[2])\n",
    "print(y[2])\n",
    "plt.imshow(x[2], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('sample_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(test_size=0.2 , log=True):\n",
    "    x_train, x_test_val, y_train, y_test_val = train_test_split(x, y, test_size=test_size,shuffle=True)\n",
    "    if log==True : \n",
    "        print('Input Shape : ')\n",
    "        print(x_train.shape,(y_train).shape)\n",
    "        print(x_test_val.shape,(y_test_val).shape)\n",
    "    x_test=x_test_val\n",
    "    x_val=x_test_val\n",
    "    y_test=y_test_val\n",
    "    y_val=y_test_val\n",
    "    \n",
    "        \n",
    "    x_train=x_train.reshape(-1,256,256,1)  \n",
    "#     y_train=y_train.reshape(-1,100,100,1)  \n",
    "#     y_test=y_test.reshape(-1,100,100,1)    \n",
    "    x_test=x_test.reshape(-1,256,256,1)\n",
    "    x_val=x_val.reshape(-1,256,256,1)\n",
    "    if log==True : \n",
    "        print('Output Shape : ')\n",
    "        print(x_train.shape,y_train.shape)\n",
    "        print(x_test.shape,y_test.shape)\n",
    "        print(x_val.shape,y_val.shape)\n",
    "    return x_train, x_test, y_train, y_test,x_val,y_val\n",
    "x_train, x_test, y_train, y_test,x_val,y_val=split_data()\n",
    "validation_dataset=(x_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model(input_shape=(256,256,1)):\n",
    "    Model = keras.models.Sequential([\n",
    "            Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=input_shape),\n",
    "            Conv2D(32,kernel_size=(3,3),activation='relu'),\n",
    "            MaxPool2D(2,2),\n",
    "            Conv2D(32,kernel_size=(3,3),activation='relu'),    \n",
    "            Conv2D(32,kernel_size=(3,3),activation='relu'),    \n",
    "            Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "            MaxPool2D(4,4),\n",
    "            Flatten() ,    \n",
    "            Dense(64,activation='relu') ,        \n",
    "            Dense(32,activation='relu') ,   \n",
    "            Dense(16,activation='relu'),\n",
    "            Dropout(rate=0.5) ,            \n",
    "            Dense(1,activation='sigmoid') ,    \n",
    "            ])\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=Build_Model()\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.compile(optimizer='adam',\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra\n",
    "\n",
    "# def make_callbacks(csv_path='my_class_log_5.csv'):\n",
    "#     early_stop=EarlyStopping(monitor='val_loss',patience=8,mode='min',restore_best_weights=False)\n",
    "#     csv_logger=CSVLogger(csv_path)\n",
    "#     callbacks =[early_stop,csv_logger]\n",
    "#     return callbacks\n",
    "# callbacks=make_callbacks()\n",
    "\n",
    "# epochs = 1\n",
    "# Model.fit(x_train, y_train, epochs=epochs,batch_size=32,verbose=1,callbacks=callbacks,validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "Model.fit(x_train, y_train, epochs=epochs,batch_size=32,verbose=1,validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.save('tumor_classification_trained_model_by_parham_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = load_model('tumor_classification_trained_model_by_parham_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_loss, Model_accuracy = Model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"it is Model accuracy: {Model_accuracy}\")\n",
    "print(f'it is Model loss: {Model_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra\n",
    "\n",
    "\n",
    "def predict_human_readable(array):\n",
    "    array=array.flatten()\n",
    "#     print(array[0])\n",
    "    result=1 if array>0.5 else 0\n",
    "    return result   \n",
    "#----------------------------------------\n",
    "def predict_on_custome_image(img_path,img_or_directory=False,plot=False):\n",
    "    dict_1={}\n",
    "    if img_or_directory==False :\n",
    "        array=cv.imread(img_path,0)\n",
    "        \n",
    "        shape_array=array.shape\n",
    "        array_1=cv.resize(array,(256,256))\n",
    "        \n",
    "        y,x=array_1.shape\n",
    "#         array_1=array_1 / 255.0\n",
    "        array=array_1.reshape(1,y,x,1)\n",
    "        #-------\n",
    "#         print(array.shape)\n",
    "        y_predict=Model.predict(array)\n",
    "        y_predict_res=predict_human_readable(y_predict)\n",
    "        \n",
    "\n",
    "        if y_predict_res== 1:\n",
    "            predicted='Tumor Detected'\n",
    "            \n",
    "        else : \n",
    "            predicted='do not have tumor'\n",
    "        \n",
    "        dict_1.update({img_path:predicted})\n",
    "        if plot==True :\n",
    "            plt.imshow(array_1,cmap='gray')\n",
    "            plt.title(predicted)\n",
    "            plt.axis('off')\n",
    "    else :\n",
    "        all_img=os.listdir(img_path)\n",
    "        image_count=len(all_img)\n",
    "#         print(all_img)\n",
    "        if plot==True :\n",
    "            rows,columns=3,ceil(image_count/3)\n",
    "            fig = plt.figure(figsize=(20, 14))\n",
    "            \n",
    "        for c,path in enumerate(all_img) :\n",
    "            lst_1=path.split('.')\n",
    "            if lst_1[1]=='jpg' or lst_1[1]=='png' or lst_1[1]=='jpeg': \n",
    "                array=cv.imread(img_path+'/'+path,0)\n",
    "    #             print(img_path+'/'+path)\n",
    "                shape_array=array.shape\n",
    "                array_1=cv.resize(array,(256,256))\n",
    "                y,x=array_1.shape\n",
    "#                 array_1=array_1 / 255.0\n",
    "#                 array_1= array_1.astype(np.float32)\n",
    "                array=array_1.reshape(1,y,x,1)\n",
    "                \n",
    "            #-------\n",
    "\n",
    "                y_predict=Model.predict(array)\n",
    "                y_predict_res=predict_human_readable(y_predict)\n",
    "                if y_predict_res==1 :\n",
    "                    predicted='Tumor Detected'\n",
    "\n",
    "                else : \n",
    "                    predicted='do not have tumor'\n",
    "                dict_1.update({path:predicted})\n",
    "                if plot==True :\n",
    "                    fig.add_subplot(rows, columns, c+1)\n",
    "                    plt.imshow(array_1,cmap='gray')\n",
    "                    plt.title(predicted)\n",
    "                    plt.axis('off')\n",
    "            else :\n",
    "                continue\n",
    "    return dict_1           \n",
    "a=predict_on_custome_image('sample_image',img_or_directory=True,plot=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_human_readable(array):\n",
    "    array = array.flatten()\n",
    "    result = 1 if array > 0.5 else 0\n",
    "    return result   \n",
    "\n",
    "def predict_on_custom_image(model, plot=False):\n",
    "    dict_1 = {}\n",
    "    \n",
    "    # Browse for an image file\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main tkinter window\n",
    "    file_path = filedialog.askopenfilename(title=\"Select Image File\", filetypes=((\"Image files\", \"*.jpg;*.jpeg;*.png;*.bmp\"), (\"All files\", \"*.*\")))\n",
    "    \n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path, 0)\n",
    "        array_1 = cv2.resize(img, (256, 256))\n",
    "        y, x = array_1.shape\n",
    "        array = array_1.reshape(1, y, x, 1)\n",
    "\n",
    "        y_predict = model.predict(array)\n",
    "        y_predict_res = predict_human_readable(y_predict)\n",
    "\n",
    "        if y_predict_res == 1:\n",
    "            predicted = 'Tumor Detected'\n",
    "        else:\n",
    "            predicted = 'No tumor detected'\n",
    "        \n",
    "        dict_1[file_path] = predicted\n",
    "        \n",
    "        if plot:\n",
    "            plt.imshow(array_1, cmap='gray')\n",
    "            plt.title(predicted)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    return dict_1   \n",
    "\n",
    "# Example usage\n",
    "# Assuming 'Model' is your trained model\n",
    "result = predict_on_custom_image(Model, plot=True)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
